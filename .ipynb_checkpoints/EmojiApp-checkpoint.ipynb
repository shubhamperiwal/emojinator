{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 11:42:28.806873 14416 deprecation_wrapper.py:119] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 11:42:28.945461 14416 deprecation_wrapper.py:119] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0819 11:42:29.023223 14416 deprecation_wrapper.py:119] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0819 11:42:29.149454 14416 deprecation_wrapper.py:119] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 11:42:29.151452 14416 deprecation_wrapper.py:119] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0819 11:42:29.182625 14416 deprecation.py:506] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0819 11:42:29.187613 14416 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0819 11:42:29.368133 14416 deprecation_wrapper.py:119] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0819 11:42:29.615353 14416 deprecation_wrapper.py:119] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0819 11:42:29.863189 14416 deprecation.py:323] From C:\\Users\\smart\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model('handEmo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emojis():\n",
    "    emojis_folder = 'emojis/'\n",
    "    emojis = []\n",
    "    for emoji in range(len(os.listdir(emojis_folder))):\n",
    "        print(emoji)\n",
    "        emojis.append(cv2.imread(emojis_folder+str(emoji)+'.png', -1))\n",
    "    return emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_predict(model, image):\n",
    "    processed = keras_process_image(image)\n",
    "    pred_probab = model.predict(processed)[0]\n",
    "    pred_class = list(pred_probab).index(max(pred_probab))\n",
    "    return max(pred_probab), pred_class\n",
    "\n",
    "def keras_process_image(img):\n",
    "    image_x = 50\n",
    "    image_y = 50\n",
    "    img = cv2.resize(img, (image_x, image_y))\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = np.reshape(img, (-1, image_x, image_y, 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay emoji on image shown on webcam \n",
    "def overlay(image, emoji, x, y, w, h):\n",
    "    emoji = cv2.resize(emoji, (w, h))\n",
    "    try:\n",
    "        image[y:y+h, x:x+w] = blend_transparent(image[y:y+h, x:x+w], emoji)\n",
    "    except Exception as e:\n",
    "#         print(\"Except overlay\", str(e))\n",
    "        pass\n",
    "    return image\n",
    "\n",
    "def blend_transparent(face_img, overlay_t_img):\n",
    "    # Split out the transparency mask from the color info\n",
    "    overlay_img = overlay_t_img[:, :, :3] #Grab RGB Planes\n",
    "    overlay_mask = overlay_t_img[:,:,3:] #And alpha plane\n",
    "    \n",
    "    # Again calculate inverse mask\n",
    "    background_mask = 255 - overlay_mask\n",
    "    \n",
    "    # Turn the masks into 3 channels, so we can use them as weights\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert images to floating point in range 0 - 1\n",
    "    face_part = (face_img * (1/255.0)) * (background_mask * (1/255.0))\n",
    "    overlay_part = (overlay_img * (1/255.0)) * (overlay_mask * (1/255.0))\n",
    "    \n",
    "    # Add them together, rescale to 8bit integer image\n",
    "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "emojis = get_emojis()\n",
    "cap = cv2.VideoCapture(0)\n",
    "x,y,w,h = 300, 50, 350, 350\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask2 = cv2.inRange(hsv, np.array([2, 50, 60]), np.array([25, 150, 255]))\n",
    "    res = cv2.bitwise_and(img, img, mask=mask2)\n",
    "    gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "    median = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    \n",
    "    kernel_square = np.ones((5,5), np.uint8)\n",
    "    dilation = cv2.dilate(median, kernel_square, iterations=2)\n",
    "    opening = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel_square)\n",
    "    ret, thresh = cv2.threshold(opening, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    thresh = thresh[y:y+h, x:x+w]\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[-2:]\n",
    "    \n",
    "    if(ret):\n",
    "        if(len(contours)>0):\n",
    "            contour = max(contours, key=cv2.contourArea)\n",
    "            if(cv2.contourArea(contour) > 2500):\n",
    "                x,y,w1,h1 = cv2.boundingRect(contour)\n",
    "                newImage = thresh[y:y+h1, x:x+w1]\n",
    "                newImage = cv2.resize(newImage, (50, 50))\n",
    "                pred_probab, pred_class = keras_predict(model, newImage)\n",
    "#                 print(pred_class, pred_probab)\n",
    "                img = overlay(img, emojis[pred_class], 400, 250, 90, 90)\n",
    "\n",
    "        x, y, w, h = 300, 50, 350, 350\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        cv2.imshow(\"Contours\", thresh)\n",
    "        k = cv2.waitKey(1)\n",
    "        if  k & 0xFF == 27 or ret==False:\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Dense, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout\n",
    "from keras.utils import np_utils, print_summary\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/image_data.csv\", header=None)\n",
    "dataset = np.array(data)\n",
    "np.random.shuffle(dataset)\n",
    "X = dataset\n",
    "Y = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0] = data[0].map(lambda x: x[-1])\n",
    "# data.to_csv('image_data.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 50\n",
    "image_y = 50\n",
    "\n",
    "#2501 because we have images of size 50x50\n",
    "#X has all the rows and columns from 1 to 2501\n",
    "X = X[:, 1:(image_x*image_y+1)]\n",
    "#\n",
    "Y = Y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5674, 2501)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:5000, :]\n",
    "X_train = X_train/255.\n",
    "X_test = X[5000:6001, :]\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.reshape(Y.shape[0], 1)\n",
    "Y_train = Y[0:5000, :]\n",
    "Y_train = Y_train.T\n",
    "Y_test = Y[5000: 6001, :]\n",
    "Y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples =  5000\n",
      "Number of test examples =  674\n",
      "X_train shape =  (5000, 2500)\n",
      "Y_train shape =  (1, 5000)\n",
      "X_test shape =  (674, 2500)\n",
      "Y_test shape =  (1, 674)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples = \", str(X_train.shape[0]))\n",
    "print(\"Number of test examples = \", str(X_test.shape[0]))\n",
    "print(\"X_train shape = \", str(X_train.shape))\n",
    "print(\"Y_train shape = \", str(Y_train.shape))\n",
    "print(\"X_test shape = \", str(X_test.shape))\n",
    "print(\"Y_test shape = \", str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 3, ..., 5, 5, 2]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (5000, 50, 50, 1)\n",
      "X test shape:  (674, 50, 50, 1)\n",
      "Y train shape:  (5000, 6)\n"
     ]
    }
   ],
   "source": [
    "train_y = np_utils.to_categorical(Y_train)\n",
    "test_y = np_utils.to_categorical(Y_test)\n",
    "\n",
    "train_y = train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y = test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 50, 50, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 50, 50, 1)\n",
    "\n",
    "print(\"X train shape: \", str(X_train.shape))\n",
    "print(\"X test shape: \", str(X_test.shape))\n",
    "print(\"Y train shape: \", str(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 6\n",
    "    model = Sequential() #EAch step is followed by next step\n",
    "    #Add convolutional layer with 32 diff filters. Each filter is responsible for getting 1 shape.\n",
    "    #Relu performs very well. Activation can be sigmoid as well\n",
    "    model.add(Conv2D(32, (5,5), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    #Next layer is MaxPooling layer. Reduces dimensionality\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "    # Conv layer of 64 filters\n",
    "    model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5), strides=(5,5), padding='same'))\n",
    "    #If they're matrix, then convert to vector\n",
    "    model.add(Flatten())\n",
    "    # Hidden input layers is 1024\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    # Dropout helps in reducing overfitting. I dont want to fit too much to training set\n",
    "    # Only 0.6% of hidden units will be active, rest will be inactive\n",
    "    model.add(Dropout(0.6))\n",
    "    # Softmax when you want to generalise output into n number of classes\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    # crossentropy is used for softmax activation\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath= \"handEmo.h5\"\n",
    "    \n",
    "    #Checkpoint used in training a very big model\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint1]\n",
    "    \n",
    "    return model, callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0817 13:27:16.627832 18392 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 674 samples\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 17s 3ms/step - loss: 0.6978 - acc: 0.6102 - val_loss: 0.5726 - val_acc: 0.6217\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.62166, saving model to handEmo.h5\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 15s 3ms/step - loss: 0.5624 - acc: 0.6284 - val_loss: 0.5348 - val_acc: 0.6276\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.62166 to 0.62760, saving model to handEmo.h5\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.5445 - acc: 0.6494 - val_loss: 0.5419 - val_acc: 0.6172\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.62760\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.5431 - acc: 0.6388 - val_loss: 0.5276 - val_acc: 0.6113\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.62760\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.5395 - acc: 0.6314 - val_loss: 0.5355 - val_acc: 0.6128\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.62760\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.5376 - acc: 0.6212 - val_loss: 0.5298 - val_acc: 0.6217\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.62760\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.5296 - acc: 0.6408 - val_loss: 0.5236 - val_acc: 0.6113\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.62760\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.5275 - acc: 0.6318 - val_loss: 0.5249 - val_acc: 0.6439\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.62760 to 0.64392, saving model to handEmo.h5\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.5270 - acc: 0.6340 - val_loss: 0.5299 - val_acc: 0.6202\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.64392\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.5279 - acc: 0.6340 - val_loss: 0.5172 - val_acc: 0.6231\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.64392\n",
      "CNN Error: 37.69%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 46, 46, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 19, 19, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 1,107,846\n",
      "Trainable params: 1,107,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, callbacks_list = keras_model(image_x, image_y)\n",
    "model.fit(X_train, train_y, validation_data=(X_test, test_y), epochs=10, batch_size=64,\n",
    "         callbacks=callbacks_list)\n",
    "scores = model.evaluate(X_test, test_y, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" %(100 - scores[1] * 100))\n",
    "print_summary(model)\n",
    "\n",
    "model.save('handEmo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

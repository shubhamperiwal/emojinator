{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x, image_y = 50, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder if it doesn't exist\n",
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_images(g_id):\n",
    "    total_pics = 1200 #CHANGE TO 1200 LATER\n",
    "    cap = cv2.VideoCapture(0) #Open webcam\n",
    "    x, y, w, h = 300, 50, 350, 350   #Remove noise (IF hand gesture is within this area only then consider it)\n",
    "    \n",
    "    create_folder(\"gestures/\" + str(g_id))\n",
    "    pic_no = 0\n",
    "    flag_start_capturing = False\n",
    "    frames = 0\n",
    "    \n",
    "    while True:\n",
    "        #Read image from webcam\n",
    "        ret, frame = cap.read() \n",
    "        #Invert the thing because webcam returns an inverted image only\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        #Convert into HSV format\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        #Using inRange which means color of this mask will be between the 2 values provided (They're the values of skin color)\n",
    "        mask2 = cv2.inRange(hsv, np.array([2, 50, 60]), np.array([25, 150, 255]))\n",
    "        res = cv2.bitwise_and(frame, frame, mask=mask2)\n",
    "        gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "        median = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        kernel_square = np.ones((5,5), np.uint8)\n",
    "        #Removes every pixel from the border of image which it thinks is background noise. Ultimately smoothens the image \n",
    "        dilation = cv2.dilate(median, kernel_square, iterations=2)\n",
    "        #USed to smoothen the image further \n",
    "        opening = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel_square)\n",
    "        \n",
    "        #Get threshold - Black & White\n",
    "        ret, thresh = cv2.threshold(opening, 30, 255, cv2.THRESH_BINARY)\n",
    "        thresh = thresh[y:y+h, x:x+w]\n",
    "        #look for contours - diff hand shapes\n",
    "        contours = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[0]\n",
    "        \n",
    "        #Check if we got any contours\n",
    "        if(len(contours) > 0):\n",
    "            contour = max(contours, key=cv2.contourArea)\n",
    "        #If area bigger than some value. Frames > 50 because after 50 frames we start capturing\n",
    "        if(cv2.contourArea(contour) > 10000 and frames > 50):\n",
    "\n",
    "            #Gives the smallest rectangle that can cover the hand\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(contour)\n",
    "            pic_no+=1\n",
    "            save_img = thresh[y1: y1+h1, x1:x1 + w1]\n",
    "            #Resize image to 50 x 50\n",
    "            save_img = cv2.resize(save_img, (image_x, image_y))\n",
    "            #Put text on screen\n",
    "            cv2.putText(frame, \"Capturing...\", (30, 60), cv2.FONT_HERSHEY_TRIPLEX, 2, (127, 255, 255))\n",
    "            #Save images into gesture folder\n",
    "            cv2.imwrite(\"gestures/\"+str(g_id)+\"/\"+str(pic_no)+\".jpg\", save_img)\n",
    "\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "        cv2.putText(frame, str(pic_no), (30,400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (127, 127, 255))\n",
    "        cv2.imshow(\"Capturing gesture\", frame)\n",
    "        cv2.imshow(\"thresh\", thresh)\n",
    "        \n",
    "        \n",
    "        keypress = cv2.waitKey(1)\n",
    "        \n",
    "        if(keypress==ord('c')):\n",
    "            if(flag_start_capturing == False):\n",
    "                flag_start_capturing= True\n",
    "            else:\n",
    "                flag_start_capturing = False\n",
    "                frames = 0\n",
    "        if(flag_start_capturing==True):\n",
    "            frames+=1\n",
    "        if(pic_no==total_pics):\n",
    "            break         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'c' to start recording\n",
      "Enter gesture no: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Press 'c' to start recording\")\n",
    "g_id = input(\"Enter gesture no: \")\n",
    "store_images(g_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
